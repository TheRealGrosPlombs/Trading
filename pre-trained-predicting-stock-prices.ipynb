{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Demo - Predicting Stock Prices with LSTM",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRealGrosPlombs/Trading/blob/main/pre-trained-predicting-stock-prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9t476KSFbt"
      },
      "source": [
        "# Predicting Stock Prices with Deep Neural Networks\n",
        "\n",
        "This project walks you through the end-to-end data science lifecycle of developing a predictive model for stock price movements with Alpha Vantage APIs and a powerful machine learning algorithm called Long Short-Term Memory (LSTM). By completing this project, you will learn the key concepts of machine learning / deep learning and build a fully functional predictive model for the stock market, all in a single Python file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z68p_q4eISQP"
      },
      "source": [
        "#@title Load Python libraries\n",
        "\n",
        "#! pip install alpha_vantage -q\n",
        "!pip install ipympl # Install if you haven't already\n",
        "#%matplotlib ipympl\n",
        "\n",
        "# pip install numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# pip install matplotlib\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# pip install alpha_vantage\n",
        "#from alpha_vantage.timeseries import TimeSeries\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import requests\n",
        "import io\n",
        "\n",
        "print(\"All libraries loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUcYIRwMIVPV"
      },
      "source": [
        "config = {\n",
        "    \"alpha_vantage\": {\n",
        "        \"key\": \"275R80U1AKOHT2EY\", # Claim your free API key here: https://www.alphavantage.co/support/#api-key\n",
        "        \"symbol\": \"IBM\",\n",
        "        \"outputsize\": \"full\",\n",
        "        \"key_adjusted_close\": \"4. close\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"window_size\": 20,\n",
        "        \"train_split_size\": 0.80,\n",
        "    },\n",
        "    \"plots\": {\n",
        "        \"show_plots\": True,\n",
        "        \"xticks_interval\": 90,\n",
        "        \"color_actual\": \"#001f3f\",\n",
        "        \"color_train\": \"#3D9970\",\n",
        "        \"color_val\": \"#0074D9\",\n",
        "        \"color_pred_train\": \"#3D9970\",\n",
        "        \"color_pred_val\": \"#0074D9\",\n",
        "        \"color_pred_test\": \"#FF4136\",\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"input_size\": 1, # since we are only using 1 feature, close price\n",
        "        \"num_lstm_layers\": 2,\n",
        "        \"lstm_size\": 32,\n",
        "        \"dropout\": 0.2,\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"device\": \"cpu\", # \"cuda\" or \"cpu\"\n",
        "        \"batch_size\": 64,\n",
        "        \"num_epoch\": 100,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"scheduler_step_size\": 40,\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYwt1apSFb6"
      },
      "source": [
        "## Data preparation: acquiring financial market data from Alpha Vantage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7bWYyArIVRq"
      },
      "source": [
        "def download_data(config, plot=False):\n",
        "  url_raw_data = 'https://raw.githubusercontent.com/TheRealGrosPlombs/Trading/refs/heads/main/ibm_stock_data.csv'\n",
        "  ibm_raw_data = pd.read_csv(url_raw_data)\n",
        "  ibm_raw_data.head()\n",
        "\n",
        "  data_close_price = ibm_raw_data[\"data_close_price\"].to_numpy()\n",
        "  data_date = ibm_raw_data[\"data_date\"].to_numpy()\n",
        "  num_data_points = len(data_date)\n",
        "  display_date_range = \"from \" + data_date[0] + \" to \" + data_date[num_data_points-1]\n",
        "  print(\"Number data points:\", num_data_points, display_date_range)\n",
        "#     # get the data from alpha vantage\n",
        "\n",
        "#     ts = TimeSeries(key=config[\"alpha_vantage\"][\"key\"])\n",
        "#     #data, meta_data = ts.get_daily_adjusted(config[\"alpha_vantage\"][\"symbol\"], outputsize=config[\"alpha_vantage\"][\"outputsize\"])\n",
        "#     data, meta_data = ts.get_daily(config[\"alpha_vantage\"][\"symbol\"], outputsize=config[\"alpha_vantage\"][\"outputsize\"])\n",
        "#     data_date = [date for date in data.keys()]\n",
        "#     data_date.reverse()\n",
        "\n",
        "#     data_close_price = [float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]]) for date in data.keys()]\n",
        "#     data_close_price.reverse()\n",
        "#     data_close_price = np.array(data_close_price)\n",
        "\n",
        "\n",
        "  if plot:\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(data_date, data_close_price, color=config[\"plots\"][\"color_actual\"])\n",
        "    xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "    x = np.arange(0,len(xticks))\n",
        "    plt.xticks(x, xticks, rotation='vertical')\n",
        "    plt.title(\"Daily close price for \" + config[\"alpha_vantage\"][\"symbol\"] + \", \" + display_date_range)\n",
        "    plt.grid(which='major', axis='y', linestyle='--')\n",
        "    plt.show()\n",
        "\n",
        "  return data_date, data_close_price, num_data_points, display_date_range\n",
        "\n",
        "data_date, data_close_price, num_data_points, display_date_range = download_data(config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H3a86TCSFb8"
      },
      "source": [
        "## Data preparation: normalizing raw financial data"
      ]
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "cybejGtRIZIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHo7IsI9ZknK"
      },
      "source": [
        "class Normalizer():\n",
        "    def __init__(self):\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "    def fit_transform(self, x):\n",
        "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
        "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
        "        normalized_x = (x - self.mu)/self.sd\n",
        "        return normalized_x\n",
        "\n",
        "    def inverse_transform(self, x):\n",
        "        return (x*self.sd) + self.mu\n",
        "\n",
        "# normalize\n",
        "scaler = Normalizer()\n",
        "normalized_data_close_price = scaler.fit_transform(data_close_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mstDxZxSFb9"
      },
      "source": [
        "## Data preparation: generating training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cinhNa4JRHu"
      },
      "source": [
        "def prepare_data_x(x, window_size):\n",
        "    # perform windowing\n",
        "    n_row = x.shape[0] - window_size + 1\n",
        "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row,window_size), strides=(x.strides[0],x.strides[0]))\n",
        "    return output[:-1], output[-1]\n",
        "\n",
        "def prepare_data_y(x, window_size):\n",
        "    # # perform simple moving average\n",
        "    # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "    # use the next day as label\n",
        "    output = x[window_size:]\n",
        "    return output\n",
        "\n",
        "def prepare_data(normalized_data_close_price, config, plot=False):\n",
        "    data_x, data_x_unseen = prepare_data_x(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "    data_y = prepare_data_y(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "\n",
        "    # split dataset\n",
        "\n",
        "    split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
        "    data_x_train = data_x[:split_index]\n",
        "    data_x_val = data_x[split_index:]\n",
        "    data_y_train = data_y[:split_index]\n",
        "    data_y_val = data_y[split_index:]\n",
        "\n",
        "    if plot:\n",
        "        # prepare data for plotting\n",
        "\n",
        "        to_plot_data_y_train = np.zeros(num_data_points)\n",
        "        to_plot_data_y_val = np.zeros(num_data_points)\n",
        "\n",
        "        to_plot_data_y_train[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(data_y_train)\n",
        "        to_plot_data_y_val[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(data_y_val)\n",
        "\n",
        "        to_plot_data_y_train = np.where(to_plot_data_y_train == 0, None, to_plot_data_y_train)\n",
        "        to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "\n",
        "        ## plots\n",
        "\n",
        "        fig = figure(figsize=(25, 5), dpi=80)\n",
        "        fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "        plt.plot(data_date, to_plot_data_y_train, label=\"Prices (train)\", color=config[\"plots\"][\"color_train\"])\n",
        "        plt.plot(data_date, to_plot_data_y_val, label=\"Prices (validation)\", color=config[\"plots\"][\"color_val\"])\n",
        "        xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "        x = np.arange(0,len(xticks))\n",
        "        plt.xticks(x, xticks, rotation='vertical')\n",
        "        plt.title(\"Daily close prices for \" + config[\"alpha_vantage\"][\"symbol\"] + \" - showing training and validation data\")\n",
        "        plt.grid(which='major', axis='y', linestyle='--')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen\n",
        "\n",
        "split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen = prepare_data(normalized_data_close_price, config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "begE6wtnJRL9"
      },
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        x = np.expand_dims(x, 2) # in our case, we have only 1 feature, so we need to convert `x` into [batch, sequence, features] for LSTM\n",
        "        self.x = x.astype(np.float32)\n",
        "        self.y = y.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.y[idx])\n",
        "\n",
        "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
        "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
        "\n",
        "print(\"Train data shape\", dataset_train.x.shape, dataset_train.y.shape)\n",
        "print(\"Validation data shape\", dataset_val.x.shape, dataset_val.y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW8JIIAzSFcA"
      },
      "source": [
        "## Defining the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ynCp-tnJROi"
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                 nn.init.constant_(param, 0.0)\n",
        "            elif 'weight_ih' in name:\n",
        "                 nn.init.kaiming_normal_(param)\n",
        "            elif 'weight_hh' in name:\n",
        "                 nn.init.orthogonal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "\n",
        "        # layer 1\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "        # reshape output from hidden cell into [batch, features] for `linear_2`\n",
        "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1)\n",
        "\n",
        "        # layer 2\n",
        "        x = self.dropout(x)\n",
        "        predictions = self.linear_2(x)\n",
        "        return predictions[:,-1]\n",
        "\n",
        "model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
        "model = model.to(config[\"training\"][\"device\"])\n",
        "# Load model dictionary from pre-trained model data\n",
        "url = 'https://raw.githubusercontent.com/TheRealGrosPlombs/Trading/refs/heads/main/ibm_stocks_model.pt'\n",
        "response = requests.get(url, stream=True)\n",
        "response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "model_data = io.BytesIO(response.content)\n",
        "model.load_state_dict(torch.load(model_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQoZ0uHGSFcD"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCzupxOyJhQh"
      },
      "source": [
        "# here we re-initialize dataloader so the data isn't shuffled, so we can plot the values by date\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "\n",
        "# put the model in eval mode instead of training mode\n",
        "model.eval()\n",
        "\n",
        "# predict on the training data, to see how well the model managed to learn and memorize\n",
        "\n",
        "predicted_train = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(train_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_train = np.concatenate((predicted_train, out))\n",
        "\n",
        "# predict on the validation data, to see how the model does\n",
        "\n",
        "predicted_val = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(val_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_val = np.concatenate((predicted_val, out))\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "\n",
        "    # prepare data for plotting, show predicted prices\n",
        "\n",
        "    to_plot_data_y_train_pred = np.zeros(num_data_points)\n",
        "    to_plot_data_y_val_pred = np.zeros(num_data_points)\n",
        "\n",
        "    to_plot_data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
        "    to_plot_data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
        "\n",
        "    to_plot_data_y_train_pred = np.where(to_plot_data_y_train_pred == 0, None, to_plot_data_y_train_pred)\n",
        "    to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "\n",
        "    # plots\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(data_date, data_close_price, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(data_date, to_plot_data_y_train_pred, label=\"Predicted prices (train)\", color=config[\"plots\"][\"color_pred_train\"])\n",
        "    plt.plot(data_date, to_plot_data_y_val_pred, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.title(\"Compare predicted prices to actual prices\")\n",
        "    xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "    x = np.arange(0,len(xticks))\n",
        "    plt.xticks(x, xticks, rotation='vertical')\n",
        "    plt.grid(which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # prepare data for plotting, zoom in validation\n",
        "\n",
        "    to_plot_data_y_val_subset = scaler.inverse_transform(data_y_val)\n",
        "    to_plot_predicted_val = scaler.inverse_transform(predicted_val)\n",
        "    to_plot_data_date = data_date[split_index+config[\"data\"][\"window_size\"]:]\n",
        "\n",
        "    # plots\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(to_plot_data_date, to_plot_data_y_val_subset, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(to_plot_data_date, to_plot_predicted_val, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
        "    xticks = [to_plot_data_date[i] if ((i%int(config[\"plots\"][\"xticks_interval\"]/5)==0 and (len(to_plot_data_date)-i) > config[\"plots\"][\"xticks_interval\"]/6) or i==len(to_plot_data_date)-1) else None for i in range(len(to_plot_data_date))] # make x ticks nice\n",
        "    xs = np.arange(0,len(xticks))\n",
        "    plt.xticks(xs, xticks, rotation='vertical')\n",
        "    plt.grid(which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-X8WO0FSFcE"
      },
      "source": [
        "## Predicting future stock prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgSOzYuXJrdU"
      },
      "source": [
        "# predict on the unseen data, tomorrow's price\n",
        "\n",
        "model.eval()\n",
        "\n",
        "x = torch.tensor(data_x_unseen).float().to(config[\"training\"][\"device\"]).unsqueeze(0).unsqueeze(2) # this is the data type and shape required, [batch, sequence, feature]\n",
        "prediction = model(x)\n",
        "prediction = prediction.cpu().detach().numpy()\n",
        "prediction = scaler.inverse_transform(prediction)[0]\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "\n",
        "    # prepare plots\n",
        "\n",
        "    plot_range = 10\n",
        "    to_plot_data_y_val = np.zeros(plot_range)\n",
        "    to_plot_data_y_val_pred = np.zeros(plot_range)\n",
        "    to_plot_data_y_test_pred = np.zeros(plot_range)\n",
        "\n",
        "    to_plot_data_y_val[:plot_range-1] = scaler.inverse_transform(data_y_val)[-plot_range+1:]\n",
        "    to_plot_data_y_val_pred[:plot_range-1] = scaler.inverse_transform(predicted_val)[-plot_range+1:]\n",
        "\n",
        "    to_plot_data_y_test_pred[plot_range-1] = prediction\n",
        "\n",
        "    to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "    to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "    to_plot_data_y_test_pred = np.where(to_plot_data_y_test_pred == 0, None, to_plot_data_y_test_pred)\n",
        "\n",
        "    # plot\n",
        "\n",
        "    plot_date_test = data_date[-plot_range+1:]\n",
        "    plot_date_test = np.append(plot_date_test,\"next trading day\")\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(plot_date_test, to_plot_data_y_val, label=\"Actual prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(plot_date_test, to_plot_data_y_val_pred, label=\"Past predicted prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.plot(plot_date_test, to_plot_data_y_test_pred, label=\"Predicted price for next day\", marker=\".\", markersize=20, color=config[\"plots\"][\"color_pred_test\"])\n",
        "    plt.title(\"Predicted close price of the next trading day\")\n",
        "    plt.grid(which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Predicted close price of the next trading day:\", round(prediction, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'ibm_stocks_model.pt')"
      ],
      "metadata": {
        "id": "33VBZds2YH-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}